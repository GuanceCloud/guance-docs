# FAQ

## 1 What to Do If Issues Occur During the First Installation and Need to Clean Up and Reinstall
**Note: This only applies to scenarios where issues occur during the first installation and a complete reinstallation is required. Please confirm carefully before proceeding with the following cleanup steps!**

If an installation issue occurs and you need to completely remove everything and reinstall, you must clean up the following three areas before starting the reinstallation of Guance from Launcher:
### 1.1 Cleanup Installed Guance Application Services
Clean up various installed Guance application services in Kubernetes. On the operation machine, enter the Launcher container and execute the built-in cleanup script of Launcher:
```
kubectl exec -it launcher-xxxxxxxx-xxx -n launcher /bin/bash
```
**launcher-xxxxxxxx-xxx is the name of your launcher service pod!**
Once inside the container, you can find the `k8s-clear.sh` script (in versions 1.47.103 and later, this script is located in the `/config/tools` directory). Execute this script to clean up all Guance application services and Kubernetes resources:

![](img/14.deployment_6.png)

### 1.2 Cleanup Automatically Created Databases in MySQL
Enter the Launcher container, which comes with the MySQL client tool, and use the following command to connect to the Guance MySQL instance:
```
mysql -h <MySQL instance host> -u root -P <MySQL port> -p  
```
You need to connect using the MySQL administrator account. After connecting, execute the following six MySQL database and user cleanup commands:
```
drop database df_core;
drop user df_core;
drop database df_message_desk;
drop user df_message_desk;
drop database df_func;
drop user df_func;
drop database df_dialtesting;
drop user df_dialtesting;
```
### 1.3 Cleanup Automatically Created Users in InfluxDB
Use the InfluxDB client tool to connect to InfluxDB and execute the following two user cleanup commands:
```
drop user user_wr;
drop user user_ro;
```
## 2 Deployment Precautions
### 2.1 Can You Manually Modify Kubernetes Resources Automatically Generated by the Installation Program After Deployment?
**Manual modifications are not allowed**, because when upgrading to a new version using Launcher, it will regenerate **Deployment, Service, Ingress** resources based on the configuration information provided at installation time (except for Configmap configurations, which can be manually modified but may cause program anomalies if done arbitrarily).

## 3 Independent Container Rancher Server Certificate Update
### 3.1 How to Handle Unexpired Certificates
The Rancher server can operate normally. After upgrading to Rancher v2.0.14+, v2.1.9+, or v2.2.2+, it will automatically check the certificate validity period. If it detects that the certificate is about to expire, it will automatically generate a new certificate. Therefore, for independently running Rancher Servers, simply upgrade the Rancher version to one that supports automatic SSL certificate updates before the certificate expires; no additional actions are needed.
### 3.2 How to Handle Expired Certificates
The Rancher server cannot operate normally. Even after upgrading to Rancher v2.0.14+, v2.1.9+, or v2.2.2+, certificate errors may still occur. If this happens, follow these steps:

1. Upgrade the Rancher version to v2.0.14+, v2.1.9+, or v2.2.2+;

2. Execute the following commands:

- For 2.0 or 2.1 versions

```shell
docker exec -ti <rancher_server_id> mv /var/lib/rancher/management-state/certs/bundle.json /var/lib/rancher/management-state/certs/bundle.json-bak
```

- For 2.2+

```shell
docker exec -ti <rancher_server_id> mv /var/lib/rancher/management-state/tls/localhost.crt /var/lib/rancher/management-state/tls/localhost.crt-bak
```

- For 2.3+

```shell
docker exec -ti <rancher_server_id> mv /var/lib/rancher/k3s/server/tls /var/lib/rancher/k3s/server/tlsbak

# Execute twice, the first for applying the certificate, the second for loading the certificate and restarting
docker restart <rancher_server_id>
```

- For 2.4+

a. Exec into the Rancher server

```shell
kubectl --insecure-skip-tls-verify -n kube-system delete secrets k3s-serving
kubectl --insecure-skip-tls-verify delete secret serving-cert -n cattle-system
rm -f /var/lib/rancher/k3s/server/tls/dynamic-cert.json
```

b. Restart the Rancher-server

```shell
docker restart <rancher_server_id>
```

c. Refresh parameters with the following command

```shell
curl --insecure -sfL https://server-url/v3
```

3. Restart the Rancher Server container

```shell
docker restart <rancher_server_id>
```
## 4 Handling Expired Rancher Server Certificates Leading to Unable to Manage K8S Clusters
If the cluster certificates have expired, even upgrading to Rancher v2.0.14, v2.1.9, or higher versions will not rotate the certificates. Rancher uses Agents to update certificates, and if the certificates expire, communication with Agents will fail.
### 4.1 Solution
Manually set the node time to a future date. Since Agents only communicate with K8S master and Rancher Server, if the Rancher Server certificate has not expired, you only need to adjust the K8S master node time.
Adjustment commands:
```shell
# Disable NTP synchronization, otherwise the time will update automatically
timedatectl set-ntp false
# Change the node time
timedatectl set-time '2019-01-01 00:00:00'
```

Then upgrade the Rancher Server and wait until the certificate rotation is complete before synchronizing the time back.
```shell
timedatectl set-ntp true
```
Check the certificate validity period
```shell
openssl x509 -in /etc/kubernetes/ssl/kube-apiserver.pem -noout -dates
```

## 5 Why Can't DataWay Be Seen on the Frontend After Creation
### 5.1 Common Cause Analysis

- The Dataway service did not start properly after being deployed on the server.
- Incorrect configuration file for the Dataway service, such as incorrect listening settings or workspace token information.
- Configuration errors in the Dataway service runtime, which can be identified by checking the Dataway logs.
- The server deploying Dataway cannot communicate with the kodo service (including the absence of correct df-kodo service resolution in hosts).
- The kodo service is abnormal, which can be confirmed by checking the kodo service logs.
- The df-kodo ingress service is incorrectly configured, specifically表现为 inability to access `http|https://df-kodo.<xxxx>:<port>`.

## 6 Why Can't Dial Testing Service Be Used
### 6.1 Cause Analysis

- The deployed Guance application is in an offline environment, and the physical nodes cannot access the internet. (Common scenario)
- Network anomaly in user-defined nodes.
- Regional provider network anomaly.
- Errors in creating dial testing tasks.

## 7 Common Deployment Issues and Solutions

### 7.1 `describe pods` Reports `unbound immediate PersistentVolumeClaims` Error

- Check PVC

```shell
NAMESPACE    NAME                                     STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE
default      opensearch-single-opensearch-single-0    Bound     pvc-0da2cb6f-1cb9-4630-b0ab-512ce57743a8   16Gi       RWO            openebs-hostpath   19d
launcher     persistent-data                          Pending                                                                        df-nfs-storage     6m3s
middleware   data-es-cluster-0                        Bound     pvc-36e48f5a-37b3-4c28-ad14-059265ee3009   50Gi       RWO            openebs-hostpath   18d
```

Notice that the status of `persistent-data` is `Pending`.

- Check the status of the `nfs-subdir-external-provisioner` container

```shell
kubectl get pods -n kube-system  | grep nfs-subdir-external-provisioner
nfs-provisioner-nfs-subdir-external-provisioner-58b7cdf6f5dr5vr   0/1     ContainerCreating   0             7h7m
```

- Check the details of `nfs-provisioner-nfs-subdir-external-provisioner-58b7cdf6f5dr5vr`

```shell
kubectl describe  -n kube-system pods nfs-provisioner-nfs-subdir-external-provisioner-58b7cdf6f5dr5vr
....
  Type     Reason       Age                     From     Message
  ----     ------       ----                    ----     -------
  Warning  FailedMount  30m (x49 over 6h53m)    kubelet  Unable to attach or mount volumes: unmounted volumes=[nfs-subdir-external-provisioner-root], unattached volumes=[kube-api-access-5p4qn nfs-subdir-external-provisioner-root]: timed out waiting for the condition
  Warning  FailedMount  5m27s (x136 over 7h4m)  kubelet  Unable to attach or mount volumes: unmounted volumes=[nfs-subdir-external-provisioner-root], unattached volumes=[nfs-subdir-external-provisioner-root kube-api-access-5p4qn]: timed out waiting for the condition
  Warning  FailedMount  74s (x217 over 7h6m)    kubelet  MountVolume.SetUp failed for volume "nfs-subdir-external-provisioner-root" : mount failed: exit status 32
Mounting command: mount
Mounting arguments: -t nfs 10.200.14.112:/nfsdata /var/lib/kubelet/pods/3970ff5f-5dbf-419e-a6af-3080508d2524/volumes/kubernetes.io~nfs/nfs-subdir-external-provisioner-root
Output: mount: wrong fs type, bad option, bad superblock on 10.200.14.112:/nfsdata,
       missing codepage or helper program, or other error
       (for several filesystems (e.g. nfs, cifs) you might
       need a /sbin/mount.<type> helper program)

       In some cases useful info is found in syslog - try
       dmesg | tail or so.
```

The error `wrong fs type, bad option` indicates that `nfs-utils` is not installed.

- Install `nfs-utils`

Execute the following command on the host:

```shell
yum install nfs-utils 
```